# 강의 제목 : LLM이 인간의 질문을 이해하는 방법

## 용어
### Attention : 각 단어가 다른 모든 단어들과 얼마나 관련있는지 점수를 매기고, 그 점수를 바탕으로 문맥적 의미를 만들어 내는 과정

---

## LLM (Large Language Model)
- 학습 데이터의 양을 기하급수적으로 늘려서 만든 Language Model

---

## LLM이 인간의 질문을 이해하는 방법
- 입력받은 문장을 분류하고 다음 단어로 뭐가 오는지 "확률적으로 계산"하는 작업을 거친다
-> 데이터가 "엄청나게 많이" 필요하다
  -> 이것이 어떻게 가능한가? 인터넷이라는 아주 큰 데이터베이스
  -> 인터넷에 있는 다양한 언어들을 전부 학습, 비지도 학습

---

## LLM(챗GPT)이 인간의 언어를 이해하고 답변하는 과정
1. 인터넷을 포함한 방대한 데이터베이스로 인간의 언어 패턴을 학습
  -> 언어 패턴 학습? 하나의 단어 뒤에 어떤 단어가 와야될 "확률"을 전부 계산
2. 그를 바탕으로 단어 하나하나 당 어떤 단어가 다음에 와야 문법에 맞고 자연스러운지 파악
  -> 이것조차 "확률"
3. 사람의 질문의 문맥과 의도를 파악
4. 파악된 문맥과 의도에 맞게 어떤 단어들을 나열해야 올바른 답변인지 "확률"적으로 계산
5. 최종적으로 단어를 조합하여 답변을 만든다

---

## 문장의 문맥을 파악하는 방법 - 단어의 중요도를 계산하라

### 단어의 중요도를 바탕으로 확률을 계산하라
- 이전의 방식(컴퓨터에게 직접 알려주는 것)과는 많이 다르다
- 이제는 AI모델에 S/W가 직접적으로 단어만 알려주면, 알고리즘만 있으면 확률에 기반하여 단어를 만들어준다

---

## 최종요약
1. AI는 결국 "데이터를 바탕으로 예측"을 하는 것이 목표
2. "대규모 데이터"를 바탕으로 "인간의 언어"에 맞게 단어의 순서를 예측하는 것이 LLM이다
  -> 대규모 데이터 : 인터넷 데이터베이스
3. 언어의 문맥 파악은 단어의 관계에서 "중요도를 점수화"하고 "확률"적으로 나타냄으로 달성 가능
4. 3번의 과정으로 문맥을 이해하는 과정을 "Attention" 이라고 하며, Attention을 탑재한 모델이 "Transfomer" 모델이다
